{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Initial data exploration:"
      ],
      "metadata": {
        "id": "XALqe6TjyWF-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading the dataset"
      ],
      "metadata": {
        "id": "q4Lf_4ecRL3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://github.com/skoltech-nlp/detox/releases/download/emnlp2021/filtered_paranmt.zip\" -O \"filtered_paranmt.zip\"\n",
        "\n",
        "!unzip \"filtered_paranmt.zip\"\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"filtered.tsv\", delimiter='\\t')"
      ],
      "metadata": {
        "id": "-9oCJvygRLQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic ideas behind data preprocessing:"
      ],
      "metadata": {
        "id": "nKIDekHtydut"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I noticed that sometimes level of toxicity for the reference is bigger than for the translation and sometimes visa versa. So I created two new lists: toxic_text, detoxed_text. And level of toxicity for the toxic_text is always greater than for the detoxed_text."
      ],
      "metadata": {
        "id": "zj64VcVPQ-H7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_df = pd.DataFrame()\n",
        "for _, row in df[:len(df)//100].iterrows():\n",
        "  if row[\"ref_tox\"] > row[\"trn_tox\"]:\n",
        "    toxic_text = row[\"reference\"]\n",
        "    detoxed_text = row[\"translation\"]\n",
        "  else:\n",
        "    toxic_text = row[\"translation\"]\n",
        "    detoxed_text = row[\"reference\"]\n",
        "\n",
        "  new_row = {\"toxic_text\": toxic_text, \"detoxed_text\": detoxed_text}\n",
        "  new_df = new_df.append(new_row, ignore_index=True)\n",
        "\n",
        "toxic_texts = new_df[\"toxic_text\"].tolist()\n",
        "detoxed_texts = new_df[\"detoxed_text\"].tolist()"
      ],
      "metadata": {
        "id": "4YU8GkzUQ8S4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}